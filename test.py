from langchain.text_splitter import RecursiveCharacterTextSplitter
from g4f.models import ModelUtils,_all_models
from g4f.Provider import ProviderUtils
from bs4 import BeautifulSoup
from docx import Document
import streamlit as st
import requests
import asyncio
import PyPDF2
import g4f
import re


class GoogleSearchExtractor:
    def __init__(self,api_key,cse_id,num_link=3,timeout_seconds=10) -> None:
        self.api_key = api_key
        self.cse_id = cse_id
        self.num_links = num_link
        self.timeout_seconds = timeout_seconds

    def google_search(self,query):
        url = "https://www.googleapis.com/customsearch/v1"
        params = {
            "q":query,
            "key":self.api_key,
            "cx":self.cse_id,
        }
        resopnse = requests.get(url,params=params)
        return resopnse.json()
    
    def clean_text(self,text):
        return re.sub(r'\s+', ' ', text).strip()
    
    def extract_contents(self,query):
        results = self.google_search(query)
        inner = []
        for item in results["items"][:self.num_links]:
            url = item['link']

            try:
                response = requests.get(url, timeout=self.timeout_seconds)
                if response.status_code == 200:
                    encoding = response.encoding if 'charset' in response.headers.get('content-type', '').lower() else None

                    # ä½¿ç”¨BeautifulSoupè§£æHTML
                    soup = BeautifulSoup(response.content, 'html.parser', from_encoding=encoding)

                    # ä½¿ç”¨get_text()æ–¹æ³•æå–æ‰€æœ‰æ–‡æœ¬å†…å®¹
                    text_content = soup.get_text()
                    # æ¸…ç†æ–‡æœ¬
                    cleaned_text = self.clean_text(text_content)
                    inner.append(cleaned_text)
                    # æ‰“å°æå–çš„æ–‡æœ¬å†…å®¹
                else:
                    print(f"æ— æ³•è®¿é—®ç½‘é¡µï¼š{url}")
            except requests.Timeout:
                print(f"è¯·æ±‚è¶…æ—¶ï¼Œè¶…è¿‡äº†{self.timeout_seconds}ç§’çš„ç­‰å¾…æ—¶é—´ã€‚é“¾æ¥ï¼š{url}")

        return inner
    

if "models_list" not in st.session_state:
    st.session_state._models_str = _all_models
    st.session_state.models_list = ModelUtils.convert
if "providers_list" not in st.session_state:
    st.session_state._providers_str = list(ProviderUtils.convert.keys())
    st.session_state.providers_list = ProviderUtils.convert
if "model" not in st.session_state:
    st.session_state["model"] = st.session_state._models_str[0]
    st.session_state["temperature"] = 0.8
    st.session_state["max_tokens"] = 2000
    st.session_state["memory"] = True
    st.session_state["g4fmodel"] = st.session_state.models_list[st.session_state["model"]]
    st.session_state["provider"] = st.session_state.providers_list[st.session_state._providers_str[0]]
    st.session_state["providers_available"] = st.session_state._providers_str
    st.session_state["stream"] = True
    st.session_state["mode"] = "**ğŸš€introudce**"
if "session" not in st.session_state:
    st.session_state["session"] = []
if "sys_prompt" not in st.session_state:
    st.session_state["sys_prompt"] = ""
if "dialogue_history" not in st.session_state:
    st.session_state["dialogue_history"] = []
if "introduce" not in st.session_state:
    with open("./README.md","r",encoding="utf-8") as f:
        st.session_state.introduce = f.read()
if "web_catcher" not in st.session_state:
    st.session_state.web_catcher = GoogleSearchExtractor(st.secrets.google_key,st.secrets.cse_id)

########################### element ###########################


header =  st.empty()
header.write("<h2> ğŸ¤– "+st.session_state["model"]+"</h2>",unsafe_allow_html=True)
show_talk = st.container()
show_test = st.container()
show_introduce = st.container()

########################### function ###########################


def collect_file(file_upload):
    file_name = ".".join(file_upload.name.split('.')[0:-1])
    file_type = file_upload.name.split('.')[-1]

    return file_name,file_type


def get_text(file,type):
    
    def extract_text_from_docx(file):
        doc = Document(file)
        text = ""
        for paragraph in doc.paragraphs:
            text += paragraph.text + "\n"
        return text
    
    def extract_text_from_pdf(file):
        pdf = PyPDF2.PdfReader(file)
        text = ""
        for page_num in range(len(pdf.pages)):
            page = pdf.pages[page_num]
            text += page.extract_text()
            
        return text
    
    # æ–‡ä»¶ç±»å‹åˆ¤æ–­
    if type == 'pdf':
        text = extract_text_from_pdf(file)
    elif type == 'docx':
        text = extract_text_from_docx(file)
    elif type == 'txt' or type == 'md' or type == 'py' or type == 'c' or type == 'cpp' or type == 'js':
        text = file.getvalue().decode("utf-8")
    else:
        print("The file type is not supported.(only pdf, docx, txt, md supported)")
        return []
    
    return text


def get_splitted_text(text):
    r_splitter = RecursiveCharacterTextSplitter(
        chunk_size=4000,
        chunk_overlap=0
    )
    return r_splitter.split_text(text)


@st.cache_data
def get_file_reader(file,type):
    sys_content = "You are a file reading bot. Next, the user will send an file. After reading, you should fully understand the content of the file and be able to analyze, interpret, and respond to questions related to the file in both Chinese and Markdown formats. Answer step-by-step."
    end_file_message = "File sent. Next, please reply in Chinese and format your response using markdown based on the content.'"
    dialogue_history = [{'role':'system','content':sys_content},]
    
    # æ–‡æœ¬æå–å¹¶æ‹†åˆ†
    text = get_text(file,type)
    text_list = get_splitted_text(text)
    pages = len(text_list)
    start_message = f"æˆ‘ç°åœ¨ä¼šå°†æ–‡ç« çš„å†…å®¹åˆ† {len(text_list)} éƒ¨åˆ†å‘é€ç»™ä½ ã€‚è¯·ç¡®ä¿ä½ å·²ç»å‡†å¤‡å¥½æ¥æ”¶ï¼Œæ¥æ”¶åˆ°æ–‡ç« å‘é€å®Œæ¯•çš„æŒ‡ä»¤åï¼Œè¯·å‡†å¤‡å›ç­”æˆ‘çš„é—®é¢˜ã€‚"
    dialogue_history.append({'role':'user','content':start_message})

    # åˆ†æ®µè¾“å…¥
    for i in range(pages):
        text_message = {'role':'user','content':text_list[i]}
        dialogue_history.append(text_message)
    
    # ç»“æŸæ–‡æœ¬è¾“å…¥
    end_message = {'role':'user','content':end_file_message}
    dialogue_history.append(end_message)

    return dialogue_history


def gpt_resopnse(model,provider,dialogue_history,temperature,max_tokens,stream):
    if stream:
        response = g4f.ChatCompletion.create(
            model=model,
            provider = provider,
            messages=dialogue_history,
            temperature=temperature, # æ§åˆ¶æ¨¡å‹è¾“å‡ºçš„éšæœºç¨‹åº¦
            max_tokens=max_tokens,  # æ§åˆ¶ç”Ÿæˆå›å¤çš„æœ€å¤§é•¿åº¦
            stream=stream
        )
    else:
        response = g4f.ChatCompletion.create(
            model=model,
            provider = provider,
            messages=dialogue_history,
            temperature=temperature, # æ§åˆ¶æ¨¡å‹è¾“å‡ºçš„éšæœºç¨‹åº¦
            max_tokens=max_tokens,  # æ§åˆ¶ç”Ÿæˆå›å¤çš„æœ€å¤§é•¿åº¦
        )
    return response

def chatg4f(message,dialogue_history,session,stream=st.session_state["stream"],model=st.session_state.g4fmodel,provider=st.session_state.provider,temperature=st.session_state.temperature,max_tokens=st.session_state.max_tokens):
    # å°†å½“å‰æ¶ˆæ¯æ·»åŠ åˆ°å¯¹è¯å†å²ä¸­
    session.append(message)
    dialogue_history.append(message)
    # å‘é€è¯·æ±‚ç»™ OpenAI GPT
    response = gpt_resopnse(model,provider,dialogue_history,temperature,max_tokens,stream)
    show()
    reply = {'role':'assistant','content':""}
    with show_talk.chat_message(reply['role']):
        line = st.empty()
        for message in response:
            reply['content'] += message
            line.empty()
            line.write(reply['content'])
    session.append(reply)
    if not st.session_state["memory"]:
        dialogue_history.pop()
    else:
        dialogue_history.append(reply)


def chatg4f_web(prompt,dialogue_history,session,stream=st.session_state["stream"],model=st.session_state.g4fmodel,provider=st.session_state.provider,temperature=st.session_state.temperature,max_tokens=st.session_state.max_tokens):
    # æ•´ç†è”ç½‘æ¶ˆæ¯
    tmp_history = [{'role':'system','content':"ä½ ç°åœ¨æ˜¯ä¸€ä¸ªå…³é”®è¯æå–æœºå™¨äºº,æ¥ä¸‹æ¥ç”¨æˆ·ä¼šç»™ä½ ä¸€æ®µæ–‡æœ¬,è¿™æ®µæ–‡æœ¬æ˜¯ç”¨æˆ·è¾“å…¥ç»™ä½ çš„å†…å®¹,è¿™æ®µå†…å®¹å¯èƒ½ä¼šæœ‰ä¸€äº›æ··æ·†çš„ä¿¡æ¯,ä½ è¦åšçš„å°±æ˜¯æå–é‡Œé¢å¯èƒ½éœ€è¦è”ç½‘æ‰èƒ½æŸ¥è¯¢åˆ°çš„ä¿¡æ¯å‡ºæ¥,å¹¶ä¸”è¿”å›æœç´¢ä½¿ç”¨çš„å…³é”®è¯ï¼Œä½ çš„å›å¤å¿…é¡»æ˜¯å…³é”®è¯,å›å¤ä¹Ÿåªèƒ½æœ‰å…³é”®è¯ï¼Œæ ¼å¼ä¸º'{key1} {key2} {key3} ...'"}]
    tmp_history.append({'role':'user','content':prompt})
    web_prompt = gpt_resopnse(model,provider,tmp_history,temperature,max_tokens,False)
    print(web_prompt)
    inner = st.session_state.web_catcher.extract_contents(web_prompt)[:3000]
    real_prompt = f"""userè¯¢é—®é—®é¢˜å¦‚ä¸‹:\n{prompt}ã€‚\n\nç½‘ç»œæœç´¢ç»“æœå¦‚ä¸‹:\n{inner}\n\nè¯·ä½ ç»“åˆç½‘ç»œæœç´¢ç»“æœå›ç­”ç”¨æˆ·çš„é—®é¢˜"""
    print(real_prompt)
    # å°†å½“å‰æ¶ˆæ¯æ·»åŠ åˆ°å¯¹è¯å†å²ä¸­
    dialogue_history.append({"role":"user","content":real_prompt})
    session.append({"role":"system","content":prompt})
    # å‘é€è¯·æ±‚ç»™ OpenAI GPT
    response = gpt_resopnse(model,provider,dialogue_history,temperature,max_tokens,stream)
    show()
    reply = {'role':'assistant','content':""}
    with show_talk.chat_message(reply['role']):
        line = st.empty()
        for message in response:
            reply['content'] += message
            line.empty()
            line.write(reply['content'])
    session.append(reply)
    if not st.session_state["memory"]:
        dialogue_history.pop()
    else:
        dialogue_history.append(reply)


def show():
    for section in st.session_state["session"]:
        with show_talk.chat_message(section['role']):
            st.write(section['content'],unsafe_allow_html=True)


########################### ä¾§è¾¹æ ï¼šè®¾ç½®ã€æµ‹è¯• ###########################


# ä¾§è¾¹æ 
with st.sidebar:

    # æ–°çš„å¼€å§‹
    with st.container():
        if st.button('New Chat',use_container_width=True):
            if st.session_state["sys_prompt"] == "":
                st.session_state["dialogue_history"] = []
            else:
                st.session_state.dialogue_history = [{'role':'system','content':st.session_state.sys_prompt},]
            st.session_state["session"] = []

    # è®¾ç½®
    with st.container():
        with st.expander("**Settings**"):
            st.session_state["model"] = st.selectbox('models', st.session_state._models_str)
            provider = st.selectbox('provider', st.session_state.providers_available)
            max_tokens = st.text_input('max_tokens', st.session_state["max_tokens"])
            memory = st.toggle('memory', st.session_state["memory"])
            st.session_state["stream"] =  st.toggle('stream', ["True","False"])
            temperature = st.slider('temperature', 0.0, 2.0, st.session_state["temperature"])
            if st.button('Save',use_container_width=True):
                st.session_state.g4fmodel = st.session_state.models_list[st.session_state["model"]]
                st.session_state.provider = st.session_state.providers_list[provider]
                st.session_state["temperature"] =temperature
                st.session_state["memory"] =memory
                st.session_state["max_tokens"] = max_tokens
                st.balloons()
                show()

    # ç³»ç»Ÿæç¤ºè¯
    with st.container():
        sys_prompt = st.text_input('**System Prompt**', st.session_state["sys_prompt"])
        st.session_state["sys_prompt"] = sys_prompt.strip()
    
    with st.container():
        new_file = st.file_uploader("ä¸Šä¼ çŸ­æ–‡ä»¶")
        if st.button('Upload FileğŸ“„',use_container_width=True) and new_file is not None:
                file_name,file_type = collect_file(new_file)
                st.session_state.dialogue_history = get_file_reader(new_file,file_type)

    # æ¨¡å¼
    with st.container():
        st.session_state["mode"] = st.radio("Choose the mode",["**ğŸš€Introduce**","**ğŸ¤–Chat**","**ğŸŒChat-web**","**ğŸ•µï¸â€â™‚ï¸Test**"])


########################### èŠå¤©å±•ç¤ºåŒº ###########################

if st.session_state["mode"] == "**ğŸ¤–Chat**":
    # ç”¨æˆ·è¾“å…¥åŒºåŸŸ
    header.write("<h2> ğŸ¤– "+st.session_state["model"]+"</h2>",unsafe_allow_html=True)
    user_prompt = st.chat_input("Send a message")
    if user_prompt:
        message = {"role":"user","content":user_prompt}
        chatg4f(message,st.session_state["dialogue_history"],st.session_state["session"])
elif st.session_state["mode"] == "**ğŸ•µï¸â€â™‚ï¸Test**":
    with show_test:
        async def run_provider(content,model,provider: g4f.Provider.BaseProvider):
            try:
                response = await g4f.ChatCompletion.create_async(
                    model=model,
                    messages=[{"role": "user", "content": content}],
                    provider=provider,
                )
                if response != "":
                    st.session_state.providers_available.append(provider.__name__)
                    show_test.write("***")
                    show_test.write(f"**{provider.__name__}:**")
                    show_test.write(response)
                # print(f"{provider.__name__}:", response)
            except Exception as e:
                # show_test.write("***")
                # show_test.write(f"*{provider.__name__}*: {e}")
                # print(f"{provider.__name__}:", e)
                pass
                
        async def run_all(content,model):
            calls = [
                run_provider(content,model,provider) for provider in st.session_state.providers_list.values()
            ]
            await asyncio.gather(*calls)

        def test_provider(content,model):
            asyncio.run(run_all(content,model))
            
    header.write("<h2> ğŸ•µï¸â€â™‚ï¸ "+st.session_state["model"]+"</h2>",unsafe_allow_html=True)
    test_prompt = st.chat_input("Send a test message to search avalible providers")
    if test_prompt:
        with st.spinner('ğŸ•µï¸â€â™‚ï¸Search available providers...'):
            st.session_state.providers_available = []
            test_provider(test_prompt,st.session_state.g4fmodel)
elif st.session_state.mode == "**ğŸŒChat-web**":
    # ç”¨æˆ·è¾“å…¥åŒºåŸŸ
    header.write("<h2> ğŸŒ "+st.session_state["model"]+"</h2>",unsafe_allow_html=True)
    user_prompt = st.chat_input("Send a message")
    if user_prompt:
        chatg4f_web(user_prompt,st.session_state["dialogue_history"],st.session_state["session"])
else:
    with show_introduce:
        header.write("<h2> ğŸš€ "+st.session_state["model"]+"</h2>",unsafe_allow_html=True)
        st.write(st.session_state.introduce)
